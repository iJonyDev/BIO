#   |  |               |  |
#   |4 |    GRÁFICO    |1 |
#   |  |               |  |
#   |lín|               |lín|
#   |  |               |ea |
#   |  |               |  |
#   +---------------------+
#   |                     |
#   |   4 líneas (bottom) |
#   |                     |
#   +---------------------+
# Para cada variable mostrar histogramas
for (i in 1:n_vars) {
# Obtener nombre de variable o asignar uno si no tiene
var_name <- ifelse(!is.null(names(preprocessed_data)),
names(preprocessed_data)[i],
paste("var", i))
# Color para esta variable
col_i <- colors[i %% length(colors) + 1]
# Histograma de datos no procesados
hist(data_no_preprocessed[[i]],
col=col_i,
main=paste("No Preprocesado:", var_name),
xlab="Valor",
ylab="Frecuencia")
# Histograma de datos preprocesados
hist(preprocessed_data[[i]],
col=col_i,
main=paste("Preprocesado",tipo_preprocesamiento,":", var_name),
xlab="Valor",
ylab="Frecuencia")
}
# Restaurar configuración de panel por defecto
par(mfrow=c(1,1))
# ---- Boxplots Antes y Despues de Transformar ----
# Configurar el panel para mostrar los boxplots
par(mfrow=c(n_vars, 2), mar=c(2,4,2,1))
# Para cada variable, mostrar boxplots
for (i in 1:n_vars) {
# Obtener nombre de variable o asignar uno si no tiene
var_name <- ifelse(!is.null(names(preprocessed_data)),
names(preprocessed_data)[i],
paste("var", i))
# Color para esta variable
col_i <- colors[i %% length(colors) + 1]
# Boxplot de datos no procesados
boxplot(data_no_preprocessed[[i]],
col=col_i,
main=paste("No Preprocesado:", var_name),
xlab="Valor",
ylab="Valor")
# Boxplot de datos preprocesados
boxplot(preprocessed_data[[i]],
col=col_i,
main=paste("Preprocesado",tipo_preprocesamiento,":", var_name),
xlab="Valor",
ylab="Valor")
# Imprimir resúmenes
cat("\n--- ", var_name, " ---\n")
cat("No Preprocesado: \n")
print(summary(data_no_preprocessed[[i]]))
cat("Preprocesado",tipo_preprocesamiento, ":\n")
print(summary(preprocessed_data[[i]]))
}
# Restaurar configuración de panel por defecto
par(mfrow=c(1,1))
library(mlbench)
library(factoextra)
library(pheatmap)
library(cluster)
library(biclust)
library(caret)
data(PimaIndiansDiabetes)
summary(PimaIndiansDiabetes[,1:8])
samplesCount = 8
data(PimaIndiansDiabetes)
summary(PimaIndiansDiabetes[,1:8])
samplesCount = 8
View(PimaIndiansDiabetes)
############
# OUTLIERS #
############
data(PimaIndiansDiabetes)
for (i in 1:8){ # Por cada columna del dataset
print(i)
dataColumn <- PimaIndiansDiabetes[,i]
# Deteccion de outliers
Q1 = quantile(dataColumn, 0.25, na.rm = TRUE)
Q3 = quantile(dataColumn, 0.75, na.rm = TRUE)
IQR=Q3-Q1
leveDown = Q1-1.5*IQR
leveUp = Q3 + 1.5 * IQR
# Recodificacion
is.na(dataColumn) <- dataColumn >= leveUp
is.na(dataColumn) <- dataColumn <= leveDown
# Reemplazar los datos en el conjunto de datos preprocesado
dataColumn[is.na(dataColumn)] <- mean(dataColumn, na.rm=TRUE)
print(summary(dataColumn))
PimaIndiansDiabetes[,i] <- dataColumn
}
# Resultado final despues del tratamiento de outliers
summary(PimaIndiansDiabetes[,1:8])
# Se aplica el metodo de estandarizacion ya que es el que mejor funciona para los algoritmos de clustering y biclustering.
preprocessParams <- preProcess(PimaIndiansDiabetes[,1:samplesCount], method=c("center", "scale"))
PimaIndiansDiabetes[,1:samplesCount] <- predict(preprocessParams, PimaIndiansDiabetes[,1:samplesCount])
summary(PimaIndiansDiabetes)
distanciasPimaIndiansDiabetes <- get_dist(PimaIndiansDiabetes[,1:samplesCount], method = "pearson")
head(round(as.matrix(distanciasPimaIndiansDiabetes), 2))[, 1:samplesCount]
distanciasPimaIndiansDiabetes
fviz_dist(distanciasPimaIndiansDiabetes,
gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
# 1) Determinar el numero optimo de clusters.
fviz_nbclust(PimaIndiansDiabetes[,1:samplesCount], kmeans, method = "gap_stat")
fviz_nbclust(PimaIndiansDiabetes[,1:samplesCount], kmeans, method = "wss")
fviz_nbclust(PimaIndiansDiabetes[,1:samplesCount], kmeans, method = "silhouette")
# 2) Visualizar pheatmap con 3 clusters
pheatmap(t(PimaIndiansDiabetes[,1:samplesCount]), cutree_cols = 3)
# 3) Ejecutar metodo de clustering
set.seed(123)
clusters.km <- kmeans(PimaIndiansDiabetes[,1:samplesCount],3,nstart = 25)
clusters.km # datos agrupados en 3 clusters
data_clus_1 <- PimaIndiansDiabetes[clusters.km$cluster == 1,]
data_clus_2 <- PimaIndiansDiabetes[clusters.km$cluster == 2,]
data_clus_3 <- PimaIndiansDiabetes[clusters.km$cluster == 3,]
# 4) Visualizar resultados
fviz_cluster(clusters.km, data = PimaIndiansDiabetes[,1:samplesCount], palette = "jco", ggtheme = theme_minimal())
##########################
# CLUSTERING: JERARQUICO #
##########################
# 1) Ejecutar metodo de clustering
clusters.hc <- hclust(dist(PimaIndiansDiabetes[,1:samplesCount]),  method = "ward.D2")
# 2) Visualizar resultados
clusters.hc
fviz_dend(clusters.hc, cex = 0.5, k = 4, palette = "jco")
#######################
# BICLUSTERING: BIMAX #
#######################
#Microarray data matrix for 80 experiments with Saccharomyces Cerevisiae organism
data(BicatYeast)
summary(BicatYeast)
# 1) Ejecutar metodo de Biclustering
bicBimax <- biclust(BicatYeast, method=BCBimax(), minc = 2, minr = 2)
# 2) Visualizar resultados
bicBimax
bicluster(BicatYeast,bicBimax) #Obtendremos 100
bicluster(BicatYeast,bicBimax)[1] #Observamos el bicluster 1
parallelCoordinates(BicatYeast, bicResult=bicBimax, number = 1)
drawHeatmap(BicatYeast,bicResult=bicBimax, number = 1)
# 2) Visualizar resultados
bicBimax
bicluster(BicatYeast,bicBimax) #Obtendremos 100
bicluster(BicatYeast,bicBimax)[1] #Observamos el bicluster 1
parallelCoordinates(BicatYeast, bicResult=bicBimax, number = 1)
drawHeatmap(BicatYeast,bicResult=bicBimax, number = 1)
# 2) Visualizar pheatmap con 3 clusters
pheatmap(t(PimaIndiansDiabetes[,1:samplesCount]), cutree_cols = 3)
# 3) Ejecutar metodo de clustering
set.seed(123)
clusters.km <- kmeans(PimaIndiansDiabetes[,1:samplesCount],3,nstart = 25)
clusters.km # datos agrupados en 3 clusters
data_clus_1 <- PimaIndiansDiabetes[clusters.km$cluster == 1,]
data_clus_2 <- PimaIndiansDiabetes[clusters.km$cluster == 2,]
data_clus_3 <- PimaIndiansDiabetes[clusters.km$cluster == 3,]
# 4) Visualizar resultados
fviz_cluster(clusters.km, data = PimaIndiansDiabetes[,1:samplesCount], palette = "jco", ggtheme = theme_minimal())
##########################
# CLUSTERING: JERARQUICO #
##########################
# 1) Ejecutar metodo de clustering
clusters.hc <- hclust(dist(PimaIndiansDiabetes[,1:samplesCount]),  method = "ward.D2")
# 2) Visualizar resultados
clusters.hc
fviz_dend(clusters.hc, cex = 0.5, k = 4, palette = "jco")
#######################
# BICLUSTERING: BIMAX #
#######################
#Microarray data matrix for 80 experiments with Saccharomyces Cerevisiae organism
data(BicatYeast)
summary(BicatYeast)
# 1) Ejecutar metodo de Biclustering
bicBimax <- biclust(BicatYeast, method=BCBimax(), minc = 2, minr = 2)
# 2) Visualizar resultados
bicBimax
bicluster(BicatYeast,bicBimax) #Obtendremos 100
bicluster(BicatYeast,bicBimax)[1] #Observamos el bicluster 1
parallelCoordinates(BicatYeast, bicResult=bicBimax, number = 1)
drawHeatmap(BicatYeast,bicResult=bicBimax, number = 1)
drawHeatmap2(BicatYeast,bicResult=bicBimax, number = 1)
library(mlbench)
library(factoextra)
library(pheatmap)
library(cluster)
library(biclust)
library(caret)
data(PimaIndiansDiabetes)
summary(PimaIndiansDiabetes[,1:8])
samplesCount = 8
############
# OUTLIERS #
############
for (i in 1:8){ # Por cada columna del dataset
print(i)
dataColumn <- PimaIndiansDiabetes[,i]
# Deteccion de outliers
Q1 = quantile(dataColumn, 0.25, na.rm = TRUE)
Q3 = quantile(dataColumn, 0.75, na.rm = TRUE)
IQR=Q3-Q1
leveDown = Q1-1.5*IQR
leveUp = Q3 + 1.5 * IQR
# Recodificacion
is.na(dataColumn) <- dataColumn >= leveUp
is.na(dataColumn) <- dataColumn <= leveDown
# Reemplazar los datos en el conjunto de datos preprocesado
dataColumn[is.na(dataColumn)] <- mean(dataColumn, na.rm=TRUE)
print(summary(dataColumn))
PimaIndiansDiabetes[,i] <- dataColumn
}
# Resultado final despues del tratamiento de outliers
summary(PimaIndiansDiabetes[,1:8])
####################
# PREPROCESAMIENTO #
####################
# Se aplica el metodo de estandarizacion ya que es el que mejor funciona para los algoritmos de clustering y biclustering.
preprocessParams <- preProcess(PimaIndiansDiabetes[,1:samplesCount], method=c("center", "scale"))
PimaIndiansDiabetes[,1:samplesCount] <- predict(preprocessParams, PimaIndiansDiabetes[,1:samplesCount])
summary(PimaIndiansDiabetes)
# 1) Determinar el numero optimo de clusters.
fviz_nbclust(PimaIndiansDiabetes[,1:samplesCount], pam, method = "gap_stat")
fviz_nbclust(PimaIndiansDiabetes[,1:samplesCount], pam, method = "wss")
fviz_nbclust(PimaIndiansDiabetes[,1:samplesCount], pam, method = "silhouette")
# 2) Visualizar pheatmap con 6 clusters
pheatmap(t(PimaIndiansDiabetes[,1:samplesCount]), cutree_cols = 6)
# 3) Ejecutar metodo de clustering
set.seed(123)
require(cluster)
pam.res <- pam(PimaIndiansDiabetes[,1:samplesCount],6)
# 4) Visualizar resultados
fviz_cluster(pam.res, geom= "point", ellipsetype = "norm")
library(mlbench)
library(factoextra)
library(pheatmap)
library(cluster)
library(biclust)
library(caret)
#######################
# BICLUSTERING: CC #
#######################
#Microarray data matrix for 80 experiments with Saccharomyces Cerevisiae organism
data(BicatYeast)
summary(BicatYeast)
# 1) Ejecutar metodo de Biclustering
bicCC <- biclust(BicatYeast, method=BCCC(), delta=0.5,  alpha=1, number=10)
?biclust
# 2) Visualizar resultados
bicCC
bicluster(BicatYeast,bicCC)
parallelCoordinates(BicatYeast, bicResult=bicCC, number = 1)
drawHeatmap(BicatYeast,bicResult=bicCC, number = 1)
drawHeatmap2(BicatYeast,bicResult=bicCC, number = 1)
parallelCoordinates(BicatYeast, bicResult=bicCC, number = 2)
drawHeatmap(BicatYeast,bicResult=bicCC, number = 2)
drawHeatmap2(BicatYeast,bicResult=bicCC, number = 2)
?biclust
library(mlbench)
library(factoextra)
library(pheatmap)
library(cluster)
library(biclust)
library(caret)
require(stats); require(graphics)
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("fabia")
BiocManager::install("fabia")
library(fabia)
#Cargar Multi_A.RData
load("./Multi_A.RData")
summary(XMulti)
#Cargar Multi_A.RData
load("/Users/jonathanquishpe/Documents/BIO/material-EPD5/Multi_A.RData")
summary(XMulti)
X <- as.matrix(XMulti)
samplesCount=ncol(X)
for (i in 1:samplesCount){ # Por cada columna del dataset
print(i)
dataColumn <- X[,i]
# Deteccion de outliers
Q1 = quantile(dataColumn, 0.25, na.rm = TRUE)
Q3 = quantile(dataColumn, 0.75, na.rm = TRUE)
IQR=Q3-Q1
leveDown = Q1-1.5*IQR
leveUp = Q3 + 1.5 * IQR
# Recodificacion
is.na(dataColumn) <- dataColumn >= leveUp
is.na(dataColumn) <- dataColumn <= leveDown
# Reemplazar los datos en el conjunto de datos preprocesado
dataColumn[is.na(dataColumn)] <- mean(dataColumn, na.rm=TRUE)
print(summary(dataColumn))
X[,i] <- dataColumn
}
# Resultado final despues del tratamiento de outliers
summary(X)
####################
# PREPROCESAMIENTO #
####################
# Se aplica el metodo de estandarizacion ya que es el que mejor funciona para los algoritmos de clustering y biclustering.
preprocessParams <- preProcess(X[,1:samplesCount], method=c("center", "scale"))
X[,1:samplesCount] <- predict(preprocessParams, X[,1:samplesCount])
summary(X)
#Clustering PAM
# 1) Determinar el numero optimo de clusters.
#fviz_nbclust(X[,1:samplesCount], pam, method = "gap_stat")
fviz_nbclust(X[,1:samplesCount], pam, method = "wss")
# 2) Visualizar pheatmap con 9 clusters
pheatmap(t(X[,1:samplesCount]), cutree_cols = 9)
# 2) Visualizar pheatmap con 9 clusters
pheatmap(t(X[,1:samplesCount]), cutree_cols = 9)
# 3) Ejecutar metodo de clustering
set.seed(123)
require(cluster)
pam.res <- pam(X[,1:samplesCount],9)
# 4) Visualizar resultados
fviz_cluster(pam.res, geom= "point", ellipsetype = "norm")
#Biclustering FABIA
resMulti1 <- fabia(X,5,0.06,300,norm=2)
extractPlot(resMulti1,ti="FABIA Multiple tissues(Su)")
plotBicluster(raMulti1,2)
plot(resMulti1,dim=c(1,2),label.tol=0.01,col.group=CMulti,lab.size=0.6)
plot(resMulti1,dim=c(1,2),label.tol=0.01,col.group=CMulti,lab.size=0.6)
plot(resMulti1,dim=c(1,2),label.tol=0.01,col.group=CMulti,lab.size=0.6)
#Biclustering FABIA
resMulti1 <- fabia(X,5,0.06,300,norm=2)
plot(resMulti1,dim=c(1,2),label.tol=0.01,col.group=CMulti,lab.size=0.6)
plot(resMulti1,dim=c(1,3),label.tol=0.01,col.group=CMulti,lab.size=0.6)
source("~/JoniDev/BIO/EPD4/Problema1/Entrega EPD4-Problema1_1.R")
# Crear una lista con las variables de interés sin preprocesar
data_no_preprocessed <- datos_recodificados
#####################################################
#### Procesado Tipo: Transformación Escala ##########
#####################################################
library(caret)
tipo_preprocesamiento <- "Transfomacion Escala"
# Procesar todas las variables a la vez usando lapply
preprocessed_results <- lapply(data_no_preprocessed, function(variable) {
var_df <- data.frame(x = variable)
params <- preProcess(var_df, method=c("scale")) # Obtener los parámetros
transformed <- predict(params, var_df) # Transformar
# Devolver los parámetros y los datos transformados
return(list(
params = params,
transformed = transformed$x
))
})
source("~/JoniDev/BIO/EPD4/Problema1/Entrega EPD4-Problema1_3.R")
library(caret)
tipo_preprocesamiento <- "Transf.Central"
# Procesar todas las variables a la vez usando lapply
preprocessed_results <- lapply(data_no_preprocessed, function(variable) {
var_df <- data.frame(x = variable) # Crear un data frame con la variable de interés
# La transformación scale calcula la desviación estándar de un atributo
# y divide cada valor por esa desviación estándar.
params <- preProcess(var_df, method=c("center")) # Transmacion central
transformed <- predict(params, var_df) # Transformar los datos
# Devolver los parámetros y los datos transformados
return(list(
params = params,
transformed = transformed$x
))
})
source("~/JoniDev/BIO/EPD4/Problema1/Entrega EPD4-Problema1_3.R")
source("~/JoniDev/BIO/EPD4/Problema1/Entrega EPD4-Problema1_3.R")
library(caret)
tipo_preprocesamiento <- "Transf.Estandarizacion "
# Procesar todas las variables a la vez usando lapply
preprocessed_results <- lapply(data_no_preprocessed, function(variable) {
var_df <- data.frame(x = variable) # Crear un data frame con la variable de interés
# La transformación scale calcula la desviación estándar de un atributo
# y divide cada valor por esa desviación estándar.
params <- preProcess(var_df, method=c("center", "scale")) # Transmacion por estandarizacion
transformed <- predict(params, var_df) # Transformar los datos
# Devolver los parámetros y los datos transformados
return(list(
params = params,
transformed = transformed$x
))
})
source("~/JoniDev/BIO/EPD4/Problema1/Entrega EPD4-Problema1_3.R")
library(caret)
tipo_preprocesamiento <- "Transf.Normalizacion "
# Procesar todas las variables a la vez usando lapply
preprocessed_results <- lapply(data_no_preprocessed, function(variable) {
var_df <- data.frame(x = variable) # Crear un data frame con la variable de interés
# La transformación scale calcula la desviación estándar de un atributo
# y divide cada valor por esa desviación estándar.
params <- preProcess(var_df, method=c("range")) # Transmacion de normalizacion
transformed <- predict(params, var_df) # Transformar los datos
# Devolver los parámetros y los datos transformados
return(list(
params = params,
transformed = transformed$x
))
})
source("~/JoniDev/BIO/EPD4/Problema1/Entrega EPD4-Problema1_3.R")
library(mlbench)
library(caret)
tipo_preprocesamiento <- "Transf.Box-Cox "
# Procesar todas las variables a la vez usando lapply
preprocessed_results <- lapply(data_no_preprocessed, function(variable) {
var_df <- data.frame(x = variable) # Crear un data frame con la variable de interés
params <- preProcess(var_df, method=c("BoxCox")) # Transmacion de BoxCox
transformed <- predict(params, var_df) # Transformar los datos
# Devolver los parámetros y los datos transformados
return(list(
params = params,
transformed = transformed$x
))
})
source("~/JoniDev/BIO/EPD4/Problema1/Entrega EPD4-Problema1_3.R")
library(mlbench)
library(caret)
tipo_preprocesamiento <- "Transf.Yeo-Johnson "
# Procesar todas las variables a la vez usando lapply
preprocessed_results <- lapply(data_no_preprocessed, function(variable) {
var_df <- data.frame(x = variable) # Crear un data frame con la variable de interés
params <- preProcess(var_df, method=c("YeoJohnson"))
transformed <- predict(params, var_df) # Transformar los datos
# Devolver los parámetros y los datos transformados
return(list(
params = params,
transformed = transformed$x
))
})
source("~/JoniDev/BIO/EPD4/Problema1/Entrega EPD4-Problema1_3.R")
library(mlbench)
tipo_preprocesamiento <- "Transf.PCA " # Análisis de Componentes Principales
# Procesar todas las variables a la vez usando lapply
preprocessed_results <- lapply(data_no_preprocessed, function(variable) {
var_df <- data.frame(x = variable) # Crear un data frame con la variable de interés
params <- preProcess(var_df, method=c("center", "scale", "pca"))
transformed <- predict(params, var_df) # Transformar los datos
# Devolver los parámetros y los datos transformados
return(list(
params = params,
transformed = transformed$x
))
})
source("~/JoniDev/BIO/EPD4/Problema1/Entrega EPD4-Problema1_3.R")
library(mlbench)
library(caret)
library(fastICA)
tipo_preprocesamiento <- "Transf.ICA " # Analisis de Componentes Independientes
# Procesar todas las variables a la vez usando lapply
preprocessed_results <- lapply(data_no_preprocessed, function(variable) {
var_df <- data.frame(x = variable) # Crear un data frame con la variable de interés
params <- preProcess(var_df, method=c("center", "scale", "ica"), n.comp=5) # Transmacion de ICA
transformed <- predict(params, var_df) # Transformar los datos
# Devolver los parámetros y los datos transformados
return(list(
params = params,
transformed = transformed$x
))
})
source("~/JoniDev/BIO/EPD4/Problema1/Entrega EPD4-Problema1_3.R")
library(caret)
tipo_preprocesamiento <- "Transfomacion Escala"
# Procesar todas las variables a la vez usando lapply
preprocessed_results <- lapply(data_no_preprocessed, function(variable) {
var_df <- data.frame(x = variable)
params <- preProcess(var_df, method=c("scale")) # Obtener los parámetros
transformed <- predict(params, var_df) # Transformar
# Devolver los parámetros y los datos transformados
return(list(
params = params,
transformed = transformed$x
))
})
source("~/JoniDev/BIO/EPD4/Problema1/Entrega EPD4-Problema1_3.R")
library(limma)
library(edgeR)
library(Glimma)
library(gplots)
library(org.Mm.eg.db)
library(RColorBrewer)
# -------------------- Cargar el dataset --------------------
# Cambiar el directorio de trabajo
setwd("/Users/jonathanquishpe/JoniDev/BIO/EPD4/Problema2")
# Cargar el dataset de RNA-Seq
seqdata <- read.delim("GSE290268_RNAseq_FPKM_data.txt", stringsAsFactors = FALSE)
head(seqdata)
dim(seqdata)
# Formatear los datos
# Eliminar la primera columna (identificadores de genes)
countdata <- seqdata[,-1]
# Almacenar los identificadores de genes como nombres de fila
rownames(countdata) <- seqdata[,1]
View(countdata)
# Calcular CPM (Counts Per Million)
myCPM <- cpm(countdata)
View(myCPM)
threshold <- myCPM > 0.5
head(threshold)
# Resumen de cuántos genes cumplen con el umbral en cada muestra
table(rowSums(threshold))
keep <- rowSums(threshold) >= 8
counts.keep <- countdata[keep,]
summary(keep)
dim(counts.keep)
counts.normalised <- myCPM[keep,]
dim(counts.normalised)
# Convertir a un objeto edgeR
dgeObj <- DGEList(counts.keep)
dgeObjNormalised <- DGEList(counts.normalised)
