############
# OUTLIERS #
############
data(PimaIndiansDiabetes)
for (i in 1:8){ # Por cada columna del dataset
print(i)
dataColumn <- PimaIndiansDiabetes[,i]
# Deteccion de outliers
Q1 = quantile(dataColumn, 0.25, na.rm = TRUE)
Q3 = quantile(dataColumn, 0.75, na.rm = TRUE)
IQR=Q3-Q1
leveDown = Q1-1.5*IQR
leveUp = Q3 + 1.5 * IQR
# Recodificacion
is.na(dataColumn) <- dataColumn >= leveUp
is.na(dataColumn) <- dataColumn <= leveDown
# Reemplazar los datos en el conjunto de datos preprocesado
dataColumn[is.na(dataColumn)] <- mean(dataColumn, na.rm=TRUE)
print(summary(dataColumn))
PimaIndiansDiabetes[,i] <- dataColumn
}
# Resultado final despues del tratamiento de outliers
summary(PimaIndiansDiabetes[,1:8])
# Se aplica el metodo de estandarizacion ya que es el que mejor funciona para los algoritmos de clustering y biclustering.
preprocessParams <- preProcess(PimaIndiansDiabetes[,1:samplesCount], method=c("center", "scale"))
PimaIndiansDiabetes[,1:samplesCount] <- predict(preprocessParams, PimaIndiansDiabetes[,1:samplesCount])
summary(PimaIndiansDiabetes)
distanciasPimaIndiansDiabetes <- get_dist(PimaIndiansDiabetes[,1:samplesCount], method = "pearson")
head(round(as.matrix(distanciasPimaIndiansDiabetes), 2))[, 1:samplesCount]
distanciasPimaIndiansDiabetes
fviz_dist(distanciasPimaIndiansDiabetes,
gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
# 1) Determinar el numero optimo de clusters.
fviz_nbclust(PimaIndiansDiabetes[,1:samplesCount], kmeans, method = "gap_stat")
fviz_nbclust(PimaIndiansDiabetes[,1:samplesCount], kmeans, method = "wss")
fviz_nbclust(PimaIndiansDiabetes[,1:samplesCount], kmeans, method = "silhouette")
# 2) Visualizar pheatmap con 3 clusters
pheatmap(t(PimaIndiansDiabetes[,1:samplesCount]), cutree_cols = 3)
# 3) Ejecutar metodo de clustering
set.seed(123)
clusters.km <- kmeans(PimaIndiansDiabetes[,1:samplesCount],3,nstart = 25)
clusters.km # datos agrupados en 3 clusters
data_clus_1 <- PimaIndiansDiabetes[clusters.km$cluster == 1,]
data_clus_2 <- PimaIndiansDiabetes[clusters.km$cluster == 2,]
data_clus_3 <- PimaIndiansDiabetes[clusters.km$cluster == 3,]
# 4) Visualizar resultados
fviz_cluster(clusters.km, data = PimaIndiansDiabetes[,1:samplesCount], palette = "jco", ggtheme = theme_minimal())
##########################
# CLUSTERING: JERARQUICO #
##########################
# 1) Ejecutar metodo de clustering
clusters.hc <- hclust(dist(PimaIndiansDiabetes[,1:samplesCount]),  method = "ward.D2")
# 2) Visualizar resultados
clusters.hc
fviz_dend(clusters.hc, cex = 0.5, k = 4, palette = "jco")
#######################
# BICLUSTERING: BIMAX #
#######################
#Microarray data matrix for 80 experiments with Saccharomyces Cerevisiae organism
data(BicatYeast)
summary(BicatYeast)
# 1) Ejecutar metodo de Biclustering
bicBimax <- biclust(BicatYeast, method=BCBimax(), minc = 2, minr = 2)
# 2) Visualizar resultados
bicBimax
bicluster(BicatYeast,bicBimax) #Obtendremos 100
bicluster(BicatYeast,bicBimax)[1] #Observamos el bicluster 1
parallelCoordinates(BicatYeast, bicResult=bicBimax, number = 1)
drawHeatmap(BicatYeast,bicResult=bicBimax, number = 1)
# 2) Visualizar resultados
bicBimax
bicluster(BicatYeast,bicBimax) #Obtendremos 100
bicluster(BicatYeast,bicBimax)[1] #Observamos el bicluster 1
parallelCoordinates(BicatYeast, bicResult=bicBimax, number = 1)
drawHeatmap(BicatYeast,bicResult=bicBimax, number = 1)
# 2) Visualizar pheatmap con 3 clusters
pheatmap(t(PimaIndiansDiabetes[,1:samplesCount]), cutree_cols = 3)
# 3) Ejecutar metodo de clustering
set.seed(123)
clusters.km <- kmeans(PimaIndiansDiabetes[,1:samplesCount],3,nstart = 25)
clusters.km # datos agrupados en 3 clusters
data_clus_1 <- PimaIndiansDiabetes[clusters.km$cluster == 1,]
data_clus_2 <- PimaIndiansDiabetes[clusters.km$cluster == 2,]
data_clus_3 <- PimaIndiansDiabetes[clusters.km$cluster == 3,]
# 4) Visualizar resultados
fviz_cluster(clusters.km, data = PimaIndiansDiabetes[,1:samplesCount], palette = "jco", ggtheme = theme_minimal())
##########################
# CLUSTERING: JERARQUICO #
##########################
# 1) Ejecutar metodo de clustering
clusters.hc <- hclust(dist(PimaIndiansDiabetes[,1:samplesCount]),  method = "ward.D2")
# 2) Visualizar resultados
clusters.hc
fviz_dend(clusters.hc, cex = 0.5, k = 4, palette = "jco")
#######################
# BICLUSTERING: BIMAX #
#######################
#Microarray data matrix for 80 experiments with Saccharomyces Cerevisiae organism
data(BicatYeast)
summary(BicatYeast)
# 1) Ejecutar metodo de Biclustering
bicBimax <- biclust(BicatYeast, method=BCBimax(), minc = 2, minr = 2)
# 2) Visualizar resultados
bicBimax
bicluster(BicatYeast,bicBimax) #Obtendremos 100
bicluster(BicatYeast,bicBimax)[1] #Observamos el bicluster 1
parallelCoordinates(BicatYeast, bicResult=bicBimax, number = 1)
drawHeatmap(BicatYeast,bicResult=bicBimax, number = 1)
drawHeatmap2(BicatYeast,bicResult=bicBimax, number = 1)
library(mlbench)
library(factoextra)
library(pheatmap)
library(cluster)
library(biclust)
library(caret)
data(PimaIndiansDiabetes)
summary(PimaIndiansDiabetes[,1:8])
samplesCount = 8
############
# OUTLIERS #
############
for (i in 1:8){ # Por cada columna del dataset
print(i)
dataColumn <- PimaIndiansDiabetes[,i]
# Deteccion de outliers
Q1 = quantile(dataColumn, 0.25, na.rm = TRUE)
Q3 = quantile(dataColumn, 0.75, na.rm = TRUE)
IQR=Q3-Q1
leveDown = Q1-1.5*IQR
leveUp = Q3 + 1.5 * IQR
# Recodificacion
is.na(dataColumn) <- dataColumn >= leveUp
is.na(dataColumn) <- dataColumn <= leveDown
# Reemplazar los datos en el conjunto de datos preprocesado
dataColumn[is.na(dataColumn)] <- mean(dataColumn, na.rm=TRUE)
print(summary(dataColumn))
PimaIndiansDiabetes[,i] <- dataColumn
}
# Resultado final despues del tratamiento de outliers
summary(PimaIndiansDiabetes[,1:8])
####################
# PREPROCESAMIENTO #
####################
# Se aplica el metodo de estandarizacion ya que es el que mejor funciona para los algoritmos de clustering y biclustering.
preprocessParams <- preProcess(PimaIndiansDiabetes[,1:samplesCount], method=c("center", "scale"))
PimaIndiansDiabetes[,1:samplesCount] <- predict(preprocessParams, PimaIndiansDiabetes[,1:samplesCount])
summary(PimaIndiansDiabetes)
# 1) Determinar el numero optimo de clusters.
fviz_nbclust(PimaIndiansDiabetes[,1:samplesCount], pam, method = "gap_stat")
fviz_nbclust(PimaIndiansDiabetes[,1:samplesCount], pam, method = "wss")
fviz_nbclust(PimaIndiansDiabetes[,1:samplesCount], pam, method = "silhouette")
# 2) Visualizar pheatmap con 6 clusters
pheatmap(t(PimaIndiansDiabetes[,1:samplesCount]), cutree_cols = 6)
# 3) Ejecutar metodo de clustering
set.seed(123)
require(cluster)
pam.res <- pam(PimaIndiansDiabetes[,1:samplesCount],6)
# 4) Visualizar resultados
fviz_cluster(pam.res, geom= "point", ellipsetype = "norm")
library(mlbench)
library(factoextra)
library(pheatmap)
library(cluster)
library(biclust)
library(caret)
#######################
# BICLUSTERING: CC #
#######################
#Microarray data matrix for 80 experiments with Saccharomyces Cerevisiae organism
data(BicatYeast)
summary(BicatYeast)
# 1) Ejecutar metodo de Biclustering
bicCC <- biclust(BicatYeast, method=BCCC(), delta=0.5,  alpha=1, number=10)
?biclust
# 2) Visualizar resultados
bicCC
bicluster(BicatYeast,bicCC)
parallelCoordinates(BicatYeast, bicResult=bicCC, number = 1)
drawHeatmap(BicatYeast,bicResult=bicCC, number = 1)
drawHeatmap2(BicatYeast,bicResult=bicCC, number = 1)
parallelCoordinates(BicatYeast, bicResult=bicCC, number = 2)
drawHeatmap(BicatYeast,bicResult=bicCC, number = 2)
drawHeatmap2(BicatYeast,bicResult=bicCC, number = 2)
?biclust
library(mlbench)
library(factoextra)
library(pheatmap)
library(cluster)
library(biclust)
library(caret)
require(stats); require(graphics)
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("fabia")
BiocManager::install("fabia")
library(fabia)
#Cargar Multi_A.RData
load("./Multi_A.RData")
summary(XMulti)
#Cargar Multi_A.RData
load("/Users/jonathanquishpe/Documents/BIO/material-EPD5/Multi_A.RData")
summary(XMulti)
X <- as.matrix(XMulti)
samplesCount=ncol(X)
for (i in 1:samplesCount){ # Por cada columna del dataset
print(i)
dataColumn <- X[,i]
# Deteccion de outliers
Q1 = quantile(dataColumn, 0.25, na.rm = TRUE)
Q3 = quantile(dataColumn, 0.75, na.rm = TRUE)
IQR=Q3-Q1
leveDown = Q1-1.5*IQR
leveUp = Q3 + 1.5 * IQR
# Recodificacion
is.na(dataColumn) <- dataColumn >= leveUp
is.na(dataColumn) <- dataColumn <= leveDown
# Reemplazar los datos en el conjunto de datos preprocesado
dataColumn[is.na(dataColumn)] <- mean(dataColumn, na.rm=TRUE)
print(summary(dataColumn))
X[,i] <- dataColumn
}
# Resultado final despues del tratamiento de outliers
summary(X)
####################
# PREPROCESAMIENTO #
####################
# Se aplica el metodo de estandarizacion ya que es el que mejor funciona para los algoritmos de clustering y biclustering.
preprocessParams <- preProcess(X[,1:samplesCount], method=c("center", "scale"))
X[,1:samplesCount] <- predict(preprocessParams, X[,1:samplesCount])
summary(X)
#Clustering PAM
# 1) Determinar el numero optimo de clusters.
#fviz_nbclust(X[,1:samplesCount], pam, method = "gap_stat")
fviz_nbclust(X[,1:samplesCount], pam, method = "wss")
# 2) Visualizar pheatmap con 9 clusters
pheatmap(t(X[,1:samplesCount]), cutree_cols = 9)
# 2) Visualizar pheatmap con 9 clusters
pheatmap(t(X[,1:samplesCount]), cutree_cols = 9)
# 3) Ejecutar metodo de clustering
set.seed(123)
require(cluster)
pam.res <- pam(X[,1:samplesCount],9)
# 4) Visualizar resultados
fviz_cluster(pam.res, geom= "point", ellipsetype = "norm")
#Biclustering FABIA
resMulti1 <- fabia(X,5,0.06,300,norm=2)
extractPlot(resMulti1,ti="FABIA Multiple tissues(Su)")
plotBicluster(raMulti1,2)
plot(resMulti1,dim=c(1,2),label.tol=0.01,col.group=CMulti,lab.size=0.6)
plot(resMulti1,dim=c(1,2),label.tol=0.01,col.group=CMulti,lab.size=0.6)
plot(resMulti1,dim=c(1,2),label.tol=0.01,col.group=CMulti,lab.size=0.6)
#Biclustering FABIA
resMulti1 <- fabia(X,5,0.06,300,norm=2)
plot(resMulti1,dim=c(1,2),label.tol=0.01,col.group=CMulti,lab.size=0.6)
plot(resMulti1,dim=c(1,3),label.tol=0.01,col.group=CMulti,lab.size=0.6)
source("~/JoniDev/BIO/EPD4/Problema1/Entrega EPD4-Problema1_1.R")
# Crear una lista con las variables de interés sin preprocesar
data_no_preprocessed <- datos_recodificados
#####################################################
#### Procesado Tipo: Transformación Escala ##########
#####################################################
library(caret)
tipo_preprocesamiento <- "Transfomacion Escala"
# Procesar todas las variables a la vez usando lapply
preprocessed_results <- lapply(data_no_preprocessed, function(variable) {
var_df <- data.frame(x = variable)
params <- preProcess(var_df, method=c("scale")) # Obtener los parámetros
transformed <- predict(params, var_df) # Transformar
# Devolver los parámetros y los datos transformados
return(list(
params = params,
transformed = transformed$x
))
})
source("~/JoniDev/BIO/EPD4/Problema1/Entrega EPD4-Problema1_3.R")
library(caret)
tipo_preprocesamiento <- "Transf.Central"
# Procesar todas las variables a la vez usando lapply
preprocessed_results <- lapply(data_no_preprocessed, function(variable) {
var_df <- data.frame(x = variable) # Crear un data frame con la variable de interés
# La transformación scale calcula la desviación estándar de un atributo
# y divide cada valor por esa desviación estándar.
params <- preProcess(var_df, method=c("center")) # Transmacion central
transformed <- predict(params, var_df) # Transformar los datos
# Devolver los parámetros y los datos transformados
return(list(
params = params,
transformed = transformed$x
))
})
source("~/JoniDev/BIO/EPD4/Problema1/Entrega EPD4-Problema1_3.R")
source("~/JoniDev/BIO/EPD4/Problema1/Entrega EPD4-Problema1_3.R")
library(caret)
tipo_preprocesamiento <- "Transf.Estandarizacion "
# Procesar todas las variables a la vez usando lapply
preprocessed_results <- lapply(data_no_preprocessed, function(variable) {
var_df <- data.frame(x = variable) # Crear un data frame con la variable de interés
# La transformación scale calcula la desviación estándar de un atributo
# y divide cada valor por esa desviación estándar.
params <- preProcess(var_df, method=c("center", "scale")) # Transmacion por estandarizacion
transformed <- predict(params, var_df) # Transformar los datos
# Devolver los parámetros y los datos transformados
return(list(
params = params,
transformed = transformed$x
))
})
source("~/JoniDev/BIO/EPD4/Problema1/Entrega EPD4-Problema1_3.R")
library(caret)
tipo_preprocesamiento <- "Transf.Normalizacion "
# Procesar todas las variables a la vez usando lapply
preprocessed_results <- lapply(data_no_preprocessed, function(variable) {
var_df <- data.frame(x = variable) # Crear un data frame con la variable de interés
# La transformación scale calcula la desviación estándar de un atributo
# y divide cada valor por esa desviación estándar.
params <- preProcess(var_df, method=c("range")) # Transmacion de normalizacion
transformed <- predict(params, var_df) # Transformar los datos
# Devolver los parámetros y los datos transformados
return(list(
params = params,
transformed = transformed$x
))
})
source("~/JoniDev/BIO/EPD4/Problema1/Entrega EPD4-Problema1_3.R")
library(mlbench)
library(caret)
tipo_preprocesamiento <- "Transf.Box-Cox "
# Procesar todas las variables a la vez usando lapply
preprocessed_results <- lapply(data_no_preprocessed, function(variable) {
var_df <- data.frame(x = variable) # Crear un data frame con la variable de interés
params <- preProcess(var_df, method=c("BoxCox")) # Transmacion de BoxCox
transformed <- predict(params, var_df) # Transformar los datos
# Devolver los parámetros y los datos transformados
return(list(
params = params,
transformed = transformed$x
))
})
source("~/JoniDev/BIO/EPD4/Problema1/Entrega EPD4-Problema1_3.R")
library(mlbench)
library(caret)
tipo_preprocesamiento <- "Transf.Yeo-Johnson "
# Procesar todas las variables a la vez usando lapply
preprocessed_results <- lapply(data_no_preprocessed, function(variable) {
var_df <- data.frame(x = variable) # Crear un data frame con la variable de interés
params <- preProcess(var_df, method=c("YeoJohnson"))
transformed <- predict(params, var_df) # Transformar los datos
# Devolver los parámetros y los datos transformados
return(list(
params = params,
transformed = transformed$x
))
})
source("~/JoniDev/BIO/EPD4/Problema1/Entrega EPD4-Problema1_3.R")
library(mlbench)
tipo_preprocesamiento <- "Transf.PCA " # Análisis de Componentes Principales
# Procesar todas las variables a la vez usando lapply
preprocessed_results <- lapply(data_no_preprocessed, function(variable) {
var_df <- data.frame(x = variable) # Crear un data frame con la variable de interés
params <- preProcess(var_df, method=c("center", "scale", "pca"))
transformed <- predict(params, var_df) # Transformar los datos
# Devolver los parámetros y los datos transformados
return(list(
params = params,
transformed = transformed$x
))
})
source("~/JoniDev/BIO/EPD4/Problema1/Entrega EPD4-Problema1_3.R")
library(mlbench)
library(caret)
library(fastICA)
tipo_preprocesamiento <- "Transf.ICA " # Analisis de Componentes Independientes
# Procesar todas las variables a la vez usando lapply
preprocessed_results <- lapply(data_no_preprocessed, function(variable) {
var_df <- data.frame(x = variable) # Crear un data frame con la variable de interés
params <- preProcess(var_df, method=c("center", "scale", "ica"), n.comp=5) # Transmacion de ICA
transformed <- predict(params, var_df) # Transformar los datos
# Devolver los parámetros y los datos transformados
return(list(
params = params,
transformed = transformed$x
))
})
source("~/JoniDev/BIO/EPD4/Problema1/Entrega EPD4-Problema1_3.R")
library(caret)
tipo_preprocesamiento <- "Transfomacion Escala"
# Procesar todas las variables a la vez usando lapply
preprocessed_results <- lapply(data_no_preprocessed, function(variable) {
var_df <- data.frame(x = variable)
params <- preProcess(var_df, method=c("scale")) # Obtener los parámetros
transformed <- predict(params, var_df) # Transformar
# Devolver los parámetros y los datos transformados
return(list(
params = params,
transformed = transformed$x
))
})
source("~/JoniDev/BIO/EPD4/Problema1/Entrega EPD4-Problema1_3.R")
BiocManager::install("Biobase")
BiocManager::install("GEOquery")
browseVignettes("GEOquery")
library(Biobase)
library(GEOquery)
library(caret)
library(cluster)
library(factoextra)
dataSetComplete <- getGEO("GDS4855", GSEMatrix=TRUE, AnnotGPL=TRUE)
#dataSetComplete <- getGEO(filename=system.file("extdata/GDS4855.soft.gz",package="GEOquery")
dataGDS <- dataSetComplete@dataTable@table
dataGDS <- na.omit(dataGDS) # Elimina NULLs automaticamente si existen en el dataset
View(dataSetComplete)
View(dataSetComplete)
View(dataGDS)
genesGDS <- dataSetComplete@dataTable@table[["IDENTIFIER"]]
samplesGDS <- colnames(dataGDS)
#samplesCount = 14
dataGDSPreProcess <- dataGDS
samplesCount = ncol(dataGDSPreProcess)
summary(dataGDSPreProcess)
############
# OUTLIERS #
############
for (i in 3:samplesCount){ # Por cada columna del dataset
# Deteccion de outliers
Q1 = quantile(dataGDSPreProcess[,i], 0.25, na.rm = TRUE)
Q3 = quantile(dataGDSPreProcess[,i], 0.75, na.rm = TRUE)
IQR=Q3-Q1
leveDown = Q1-1.5*IQR
leveUp = Q3 + 1.5 * IQR
media = mean(dataGDSPreProcess[,i])
is.na(dataGDSPreProcess[,i]) <- dataGDSPreProcess[,i] >= leveUp
dataGDSPreProcess[,i][is.na(dataGDSPreProcess[,i])] <- media
}
summary(dataGDSPreProcess)
#################
# PREPROCESSING #
#################
preprocessParams <- preProcess(dataGDSPreProcess[,3:samplesCount], method=c("center", "scale")) # Metodo de estandarizacion
dataGDSPreProcess[,3:samplesCount] <- predict(preprocessParams, dataGDSPreProcess[,3:samplesCount])
summary(dataGDSPreProcess)
######################
# CLUSTERING: KMEANS #
######################
# Optimal number of clusters KMeans
wss <- (nrow(dataGDSPreProcess[,3:samplesCount])-1)*sum(apply(dataGDSPreProcess[,3:samplesCount],2,var))
for (i in 2:15) wss[i] <- sum(kmeans(dataGDSPreProcess[,3:samplesCount],centers=i,iter.max=80)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares")
numClusters = 14 # Optimal number of clusters KMeans. Probemos con 6 clusters y con 14.
set.seed(100)
clusters <- kmeans(dataGDSPreProcess[,3:samplesCount],numClusters,iter.max=80)
clusters # 96,8 % de datos bien agrupados con 14 clusters.
data_clus_1 <- dataGDSPreProcess[clusters$cluster == 1,]
data_clus_9 <- dataGDSPreProcess[clusters$cluster == 9,]
data_clus_5 <- dataGDSPreProcess[clusters$cluster == 5,]
data_clus_3 <- dataGDSPreProcess[clusters$cluster == 3,]
all_genes <- dataGDSPreProcess[,2]
write.table(data_clus_1$IDENTIFIER, file="./cluster_1.txt", sep = "\t", row.names = FALSE, col.names = FALSE)
write.table(data_clus_9$IDENTIFIER, file="./cluster_9.txt", sep = "\t", row.names = FALSE, col.names = FALSE)
write.table(data_clus_5$IDENTIFIER, file="./cluster_5.txt", sep = "\t", row.names = FALSE, col.names = FALSE)
write.table(data_clus_3$IDENTIFIER, file="./cluster_3.txt", sep = "\t", row.names = FALSE, col.names = FALSE)
write.table(all_genes, file="./all_genes.txt", sep = "\t", row.names = FALSE, col.names = FALSE)
library(limma)
library(edgeR)
library(Glimma)
library(gplots)
library(org.Mm.eg.db)
library(RColorBrewer)
# -------------------- Cargar el dataset --------------------
# Cambiar el directorio de trabajo
setwd("/Users/jonathanquishpe/JoniDev/BIO/EPD4/Problema2")
# Cargar el dataset de RNA-Seq
seqdata <- read.delim("GSE290268_RNAseq_FPKM_data.txt", stringsAsFactors = FALSE)
head(seqdata)
dim(seqdata)
# Formatear los datos
# Eliminar la primera columna (identificadores de genes)
countdata <- seqdata[,-1]
# Almacenar los identificadores de genes como nombres de fila
rownames(countdata) <- seqdata[,1]
View(countdata)
##############################################################
# ---------------- Preprocesamiento CPM ---------------------#
##############################################################
# Calcular CPM (Counts Per Million)
myCPM <- cpm(countdata)
View(myCPM)
# -------- Detectar y Filtrar genes de baja expresión --------
# Definir un umbral de expresión (CPM > 0.5)
threshold <- myCPM > 0.5
head(threshold)
# Resumen de cuántos genes cumplen con el umbral en cada muestra
table(rowSums(threshold))
# Mantener genes con al menos 8 muestras que cumplen el umbral
keep <- rowSums(threshold) >= 8
counts.keep <- countdata[keep,]
summary(keep)
dim(counts.keep)
# -------- Normalizar y generar nuevo conjunto de datos --------
# Normalizar los datos usando CPM
counts.normalised <- myCPM[keep,]
dim(counts.normalised)
# Convertir a un objeto edgeR
dgeObj <- DGEList(counts.keep)
dgeObjNormalised <- DGEList(counts.normalised)
##############################################################
# ---------------- Preprocesamiento RPKM ---------------------#
##############################################################
# Primero necesitamos la longitud de los genes
# Asumiendo que tienes un vector gene.length con las longitudes de los genes
# Si no lo tienes, necesitarás obtenerlo de tu anotación genómica
# Calcular RPKM
myRPKM <- rpkm(countdata, gene.length = gene.length)
